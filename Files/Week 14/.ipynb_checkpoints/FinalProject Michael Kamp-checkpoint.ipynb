{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a367b63-0c64-43d9-b13b-d82fb101ea1c",
   "metadata": {},
   "source": [
    "# Predicting Youth Mental Health Risk\n",
    "\n",
    "Student: Michael Kamp  \n",
    "\n",
    "## 1. Business Understanding\n",
    "\n",
    "This notebook supports the final project for DATA 747 and focuses on predicting poor mental-health outcomes among U.S. high-school students using the 2019 CDC Youth Risk Behavior Surveillance System (YRBSS) dataset.\n",
    "\n",
    "The goal of this analysis is to explore behavioral and demographic factors associated with the likelihood that a student reports persistent sadness or hopelessness (QN8). Using this dataset, we will prepare the data, conduct exploratory analysis, train supervised machine-learning models, and evaluate their predictive performance.\n",
    "\n",
    "**Research Question:**  \n",
    "What factors help predict whether a high-school student reports poor mental health (defined as persistent sadness/hopelessness for two or more weeks)?\n",
    "\n",
    "**Notebook Roadmap**\n",
    "1. **Data Understanding** – Review dataset structure and key variables.  \n",
    "2. **Data Preparation** – Clean the data, handle missing values, and select variables.  \n",
    "3. **Exploratory Data Analysis (EDA)** – Visualize distributions and relationships among features.  \n",
    "4. **Modeling** – Train and evaluate logistic regression and decision-tree classifiers.  \n",
    "5. **Model Evaluation** – Generate confusion matrices, ROC curves, and other performance metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af760a8-db82-49e4-b56d-00e9b947dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1 — DATA LOADING\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "data_file = \"yrbs2019.dat\"\n",
    "sas_layout = \"yrbs2019_input.sas\"\n",
    "\n",
    "# ---- Custom SAS parser (reads @start variable width.) ----\n",
    "def parse_sas_input_pointer_format(file_path):\n",
    "    colspecs = []\n",
    "    names = []\n",
    "    pattern = re.compile(r\"@(\\d+)\\s+(\\w+)\\s+(\\$?)(\\d+)\")\n",
    "\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    entries = []\n",
    "    for line in lines:\n",
    "        match = pattern.search(line)\n",
    "        if match:\n",
    "            start = int(match.group(1)) - 1          # convert 1-based to 0-based index\n",
    "            name = match.group(2)\n",
    "            width = int(match.group(4))\n",
    "            end = start + width\n",
    "            entries.append((start, end, name))\n",
    "\n",
    "    entries.sort(key=lambda x: x[0])\n",
    "\n",
    "    for start, end, name in entries:\n",
    "        colspecs.append((start, end))\n",
    "        names.append(name)\n",
    "\n",
    "    return colspecs, names\n",
    "\n",
    "# ---- Parse SAS input layout ----\n",
    "colspecs, names = parse_sas_input_pointer_format(sas_layout)\n",
    "print(\"Columns detected:\", len(names))\n",
    "\n",
    "# ---- Load FIXED-WIDTH YRBS 2019 dataset ----\n",
    "data = pd.read_fwf(data_file, colspecs=colspecs, names=names)\n",
    "\n",
    "# Preview\n",
    "print(\"First 10 rows:\")\n",
    "display(data.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9f948-6af3-4511-a7ae-5585f73343c1",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "\n",
    "This section provides an initial examination of the 2019 CDC Youth Risk Behavior Surveillance System (YRBSS) dataset. The dataset contains a wide range of demographic, behavioral, and health-related variables reported by high-school students across the United States. Before preparing the data for modeling, it is essential to understand the structure, content, and quality of the dataset.\n",
    "\n",
    "### Objectives of Data Understanding\n",
    "1. **Confirm that the dataset loaded correctly** using the CDC SAS layout file to extract column positions and variable names.\n",
    "2. **Review dataset structure**, including the number of rows, columns, and variable data types.\n",
    "3. **Identify major characteristics of key demographic variables** such as sex (Q2), grade (Q3), and race/ethnicity (Q4).\n",
    "4. **Examine the distribution of the mental-health target variable (QN8)**, which indicates whether a student felt sad or hopeless for two or more weeks.\n",
    "5. **Assess missing data**, which is important because the YRBSS uses special numeric codes (e.g., 7, 8, 9, 77, 88, 99) to represent non-responses.\n",
    "6. **Explore early distributions** of selected behavioral and health variables relevant to the research question.\n",
    "\n",
    "### Why This Matters\n",
    "A thorough understanding of the dataset ensures that the next step—data preparation—is performed accurately and effectively. Identifying missing values, variable types, and preliminary patterns informs decisions about cleaning, recoding, and selecting features for modeling.\n",
    "\n",
    "The visualizations and summary statistics in this section help lay the foundation for exploratory data analysis and model development in later sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04172e-300d-489f-9d19-90c28a4a6ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UNDERSTANDING\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Preview of dataset:\")\n",
    "display(data.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(data.describe(include='all'))\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData types:\")\n",
    "display(data.dtypes)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "display(data.isnull().sum())\n",
    "\n",
    "# Examine unique values in key demographic variables\n",
    "categorical_cols = ['Q2', 'Q3', 'Q6', 'RACEETH']\n",
    "\n",
    "print(\"\\nUnique values for categorical variables:\")\n",
    "for col in categorical_cols:\n",
    "    if col in data.columns:\n",
    "        print(f\"{col}: {data[col].unique()}\")\n",
    "\n",
    "# Explore distributions of important numeric variables\n",
    "numeric_cols = ['BMIPCT', 'QNDAYEVP', 'QN12', 'QNDAYCIG']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in data.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        data[col].hist(bins=20, color='skyblue', edgecolor='black')\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()\n",
    "\n",
    "# Target variable distribution (QN8: sad/hopeless 2+ weeks)\n",
    "if 'QN8' in data.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    data['QN8'].value_counts(dropna=False).plot(kind='bar', color=['red','green'])\n",
    "    plt.title(\"Distribution of QN8 (Persistent Sadness / Hopelessness)\")\n",
    "    plt.xlabel(\"Response\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46726a44-f726-4151-aeb6-ba186f5b5eaa",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "This section prepares the YRBSS dataset for modeling by cleaning the data, selecting relevant variables, handling missing values, encoding categorical fields, and splitting the data into training and testing sets. Because the dataset is stored in a fixed-width format and includes CDC-coded missing values, several preprocessing steps are required before fitting machine-learning models.\n",
    "\n",
    "### Objectives of Data Preparation\n",
    "1. **Clean and standardize the dataset** by replacing CDC-coded missing values with `NaN`.\n",
    "2. **Select the variables most relevant to predicting mental-health outcomes**, including demographic, behavioral, and health indicators.\n",
    "3. **Convert categorical variables** (e.g., sex, grade, age group, race/ethnicity) into appropriate data types.\n",
    "4. **Transform categorical fields using one-hot encoding** so they can be used by machine-learning algorithms.\n",
    "5. **Drop incomplete rows** to ensure a consistent and reliable modeling dataset.\n",
    "6. **Separate features (X) from the target variable (y)** and prepare them for model training.\n",
    "7. **Scale numeric predictors** using StandardScaler for the logistic regression model.\n",
    "8. **Create a train–test split** using stratified sampling to preserve the distribution of the mental-health outcome.\n",
    "\n",
    "### Why These Steps Are Necessary\n",
    "The YRBSS dataset uses a mixture of coded categorical values and non-standard missing-data indicators. Preparing the data properly ensures that:\n",
    "\n",
    "- the machine-learning models receive consistent and meaningful inputs,\n",
    "- categorical variables are encoded without introducing bias,\n",
    "- scaled variables improve optimization for logistic regression,\n",
    "- and the training/testing evaluation reflects the true distribution of mental-health outcomes.\n",
    "\n",
    "At the end of this section, the dataset is fully prepared for modeling using logistic regression and decision-tree classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b21648-ce2a-4034-a1d7-a1772193fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPARATION\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# 1. Replace CDC-coded missing values with NaN\n",
    "coded_missing = [7, 8, 9, 77, 88, 99]\n",
    "data = data.replace(coded_missing, np.nan)\n",
    "\n",
    "# 2. Select relevant variables for modeling\n",
    "selected_columns = [\n",
    "    'Q2',          # Sex\n",
    "    'Q3',          # Grade\n",
    "    'Q6',          # Age category\n",
    "    'RACEETH',     # Race / Ethnicity\n",
    "\n",
    "    'QN8',         # Target: sad/hopeless ≥2 weeks\n",
    "\n",
    "    'QN12',        # Alcohol use\n",
    "    'QNDAYEVP',    # E-cigarette use (days)\n",
    "    'QNDAYCIG',    # Cigarette use (days)\n",
    "    'QNSODA1',     # Soda consumption\n",
    "    'QNPA0DAY',    # No physical activity\n",
    "    'QNOBESE',     # Obesity status\n",
    "    'BMIPCT'       # BMI percentile\n",
    "]\n",
    "\n",
    "selected_columns = [c for c in selected_columns if c in data.columns]\n",
    "cleaned = data[selected_columns].copy()\n",
    "\n",
    "# 3. Convert demographic variables to categorical\n",
    "categorical_vars = ['Q2', 'Q3', 'Q6', 'RACEETH']\n",
    "\n",
    "for col in categorical_vars:\n",
    "    if col in cleaned.columns:\n",
    "        cleaned[col] = cleaned[col].astype('category')\n",
    "\n",
    "# 4. Convert remaining variables to numeric\n",
    "for col in cleaned.columns:\n",
    "    if col not in categorical_vars:\n",
    "        cleaned[col] = pd.to_numeric(cleaned[col], errors='coerce')\n",
    "\n",
    "# 5. Drop rows with missing values for modeling\n",
    "rows_before = cleaned.shape[0]\n",
    "cleaned = cleaned.dropna()\n",
    "rows_after = cleaned.shape[0]\n",
    "\n",
    "print(f\"Rows before dropping missing values: {rows_before}\")\n",
    "print(f\"Rows after dropping missing values:  {rows_after}\")\n",
    "print(f\"Total rows removed:                  {rows_before - rows_after}\")\n",
    "\n",
    "# 6. Split into features (X) and target (y)\n",
    "y = (cleaned['QN8'] == 1).astype(int)\n",
    "X = cleaned.drop('QN8', axis=1)\n",
    "\n",
    "# 7. One-hot encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"Shape after encoding:\", X.shape)\n",
    "\n",
    "# 8. Train/Test Split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"Training target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# 9. Standard Scaling (Logistic Regression only)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nScaling complete.\")\n",
    "print(\"Scaled X_train shape:\", X_train_scaled.shape)\n",
    "print(\"Scaled X_test shape:\", X_test_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e9fb0-dfb2-410c-a0ac-d7a5aa014b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "This section explores the structure and key characteristics of the variables included in the study. Exploratory Data Analysis helps identify patterns,\n",
    "trends, and potential relationships in the dataset prior to modeling. Because the YRBSS includes a broad range of demographic, behavioral,and health variables,\n",
    "EDA is essential for understanding which factors may be associated with poor mental-health outcomes.\n",
    "\n",
    "### Objectives of EDA\n",
    "1. **Examine the distribution of demographic variables**, including sex (Q2), grade level (Q3), and race/ethnicity (Q4), to understand population composition.\n",
    "2. **Visualize the distribution of the target variable (QN8)**, which indicates whether a student experienced persistent sadness or hopelessness.\n",
    "3. **Explore behavioral indicators** such as alcohol use, vaping, smoking, soda consumption, and physical inactivity.\n",
    "4. **Compare mental-health outcomes across demographic and behavioral subgroups** using side-by-side count plots.\n",
    "5. **Generate a correlation heatmap** to identify relationships among numeric variables, such as BMI percentile and behavioral frequency indicators.\n",
    "\n",
    "### Why This Matters\n",
    "EDA provides an essential foundation for modeling. Visualizing these variables allows us to quickly identify imbalances, unusual values, and potential predictors. \n",
    "Understanding how mental-health outcomes vary across demographic and behavioral groups helps guide feature selection and interpret model performance in later sections.\n",
    "\n",
    "The visualizations in this section highlight important structures within the dataset and support the development of more effective predictive models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09f53a-573b-4eea-a59a-6a07124420fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (with plot saving)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Ensure folder exists\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "\n",
    "# Summary Statistics\n",
    "\n",
    "display(data.describe(include='all'))\n",
    "display(data.dtypes)\n",
    "\n",
    "\n",
    "# Demographic Distributions\n",
    "demo_vars = [\"Q2\", \"Q3\", \"Q4\"]\n",
    "\n",
    "for col in demo_vars:\n",
    "    if col in data.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        data[col].value_counts(dropna=False).plot(kind=\"bar\", color=\"steelblue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Count\")\n",
    "\n",
    "        # Save chart\n",
    "        plt.savefig(f\"plots/EDA_distribution_{col}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Missing Data Chart\n",
    "missing = data.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=missing.head(20).index, y=missing.head(20).values, palette=\"viridis\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Top Missing Variables\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"plots/EDA_missing_values.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Numeric Variable Distributions\n",
    "numeric_cols = ['BMIPCT', 'QNDAYEVP', 'QN12', 'QNDAYCIG']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in data.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        data[col].hist(bins=20, color=\"lightgreen\", edgecolor=\"black\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel(\"Frequency\")\n",
    "\n",
    "        plt.savefig(f\"plots/EDA_numeric_{col}.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Target Variable (QN8)\n",
    "if \"QN8\" in data.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    data[\"QN8\"].value_counts(dropna=False).plot(kind=\"bar\", color=[\"red\",\"green\"])\n",
    "    plt.title(\"Distribution of QN8 (Sad/Hopeless 2+ Weeks)\")\n",
    "    plt.xlabel(\"Response\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "    plt.savefig(\"plots/EDA_target_QN8.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bafc57-7315-4387-af77-19ed1600b1ea",
   "metadata": {},
   "source": [
    "## 5. Modeling\n",
    "\n",
    "In this section, we build predictive models to identify factors associated with poor mental-health outcomes among high-school students. Using the cleaned and prepared dataset from the previous section, we apply two supervised machine-learning algorithms:\n",
    "\n",
    "1. **Logistic Regression** – A linear classification model used as a baseline to predict the likelihood that a student reports persistent sadness or hopelessness (QN8). Logistic regression is effective when the relationship between predictors and the target variable is approximately linear and when interpretability is important.\n",
    "\n",
    "2. **Decision Tree Classifier** – A non-linear model capable of capturing complex interactions between demographic, behavioral, and health variables. Decision trees can identify the most influential predictors by recursively splitting the dataset into meaningful subgroups.\n",
    "\n",
    "### Modeling Workflow\n",
    "- The dataset is split into training and testing sets using stratified sampling to preserve the distribution of the mental-health outcome.\n",
    "- Logistic regression is trained on **scaled** inputs to improve stability and performance.\n",
    "- The decision-tree classifier is trained on **unscaled** inputs, since tree-based models are not sensitive to feature scaling.\n",
    "- Each model generates predictions on the testing set and is evaluated using accuracy, precision, recall, F1-score, and a classification report.\n",
    "\n",
    "### Purpose of This Section\n",
    "By fitting both a linear and a non-linear model, we can compare performance and better understand the predictive structure of the YRBSS dataset. This provides insight into which model is best suited for identifying students at elevated mental-health risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118a1422-23e9-42bf-b768-ee8b79fbbde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING: Logistic Regression and Decision Tree Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "print(\"=== MODELING SECTION ===\\n\")\n",
    "\n",
    "\n",
    "# Logistic Regression (uses scaled features)\n",
    "log_model = LogisticRegression(max_iter=500, solver=\"lbfgs\")\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "log_pred = log_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation\n",
    "log_accuracy = accuracy_score(y_test, log_pred)\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, log_pred))\n",
    "\n",
    "# Decision Tree Classifier (uses unscaled features)\n",
    "tree_model = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "tree_accuracy = accuracy_score(y_test, tree_pred)\n",
    "print(f\"Decision Tree Accuracy: {tree_accuracy:.4f}\")\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, tree_pred))\n",
    "\n",
    "\n",
    "# Model Comparison Summary\n",
    "print(\"=== MODEL COMPARISON SUMMARY ===\")\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(f\"Decision Tree Accuracy:      {tree_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda5ca5c-8f91-4895-b26b-48511dbe8139",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "After training the logistic regression and decision-tree models, this section evaluates their performance on the testing dataset. Model evaluation provides insight into how effectively each classifier identifies students who report poor mental-health outcomes and how well the models generalize to new, unseen data.\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "To assess each model, we use several common classification performance measures:\n",
    "\n",
    "- **Confusion Matrix:**  \n",
    "  Displays true positives, true negatives, false positives, and false negatives.  \n",
    "  This helps identify how often each model correctly classifies students with and without reported sadness/hopelessness.\n",
    "\n",
    "- **Classification Report:**  \n",
    "  Includes precision, recall, F1-score, and support for each class.  \n",
    "  These metrics are especially important given the imbalance in mental-health outcomes.\n",
    "\n",
    "- **ROC Curve (Receiver Operating Characteristic):**  \n",
    "  Shows the trade-off between the true positive rate and false positive rate across different thresholds.\n",
    "\n",
    "- **AUC (Area Under the Curve):**  \n",
    "  Summarizes how well a model distinguishes between students who reported persistent sadness and those who did not.  \n",
    "  Higher AUC values indicate stronger discriminative ability.\n",
    "\n",
    "- **Feature Importance (Decision Tree):**  \n",
    "  Highlights which demographic, behavioral, or health-related factors contribute most strongly to the decision-tree model’s predictions.\n",
    "\n",
    "### Purpose of This Section\n",
    "This evaluation helps determine which model performs best and provides insight into the patterns within the dataset. Understanding model strengths and weaknesses supports the interpretation of results in the accompanying APA report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bfd1a-9c14-4c43-b508-6999a79e0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MODEL EVALUATION (Saved Plots)\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    RocCurveDisplay,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# Ensure plots/ folder exists\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "print(\"=== MODEL EVALUATION SECTION ===\\n\")\n",
    "\n",
    "# 1. CONFUSION MATRICES\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Logistic Regression\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    log_model, X_test_scaled, y_test,\n",
    "    cmap=\"Blues\", ax=axes[0]\n",
    ")\n",
    "axes[0].set_title(\"Logistic Regression – Confusion Matrix\")\n",
    "\n",
    "# Decision Tree\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    tree_model, X_test, y_test,\n",
    "    cmap=\"Greens\", ax=axes[1]\n",
    ")\n",
    "axes[1].set_title(\"Decision Tree – Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/confusion_matrices.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: plots/confusion_matrices.png\")\n",
    "\n",
    "# 2. ROC CURVES + AUC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# AUC values\n",
    "log_auc = roc_auc_score(y_test, log_model.predict_proba(X_test_scaled)[:, 1])\n",
    "tree_auc = roc_auc_score(y_test, tree_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# ROC curves\n",
    "RocCurveDisplay.from_estimator(\n",
    "    log_model, X_test_scaled, y_test,\n",
    "    name=f\"Logistic Regression (AUC = {log_auc:.2f})\",\n",
    "    color=\"blue\"\n",
    ")\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    tree_model, X_test, y_test,\n",
    "    name=f\"Decision Tree (AUC = {tree_auc:.2f})\",\n",
    "    color=\"green\"\n",
    ")\n",
    "\n",
    "# Random baseline\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Random Guess\")\n",
    "\n",
    "# Determine best model\n",
    "best_model_name = \"Logistic Regression\" if log_auc > tree_auc else \"Decision Tree\"\n",
    "best_model_auc = max(log_auc, tree_auc)\n",
    "\n",
    "# Add annotation box\n",
    "plt.text(\n",
    "    0.60, 0.15,\n",
    "    f\"Best Model: {best_model_name}\\nAUC = {best_model_auc:.2f}\",\n",
    "    fontsize=12,\n",
    "    bbox=dict(facecolor=\"white\", edgecolor=\"black\", alpha=0.85)\n",
    ")\n",
    "\n",
    "plt.title(\"ROC Curve Comparison\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.savefig(\"plots/roc_curve_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: plots/roc_curve_comparison.png\")\n",
    "\n",
    "# 3. DECISION TREE FEATURE IMPORTANCE\n",
    "importances = tree_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(\n",
    "    data=imp_df.head(20),\n",
    "    x=\"Importance\", y=\"Feature\",\n",
    "    palette=\"viridis\"\n",
    ")\n",
    "\n",
    "plt.title(\"Top 20 Feature Importances – Decision Tree\")\n",
    "plt.xlabel(\"Importance Score\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"plots/decision_tree_feature_importances.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: plots/decision_tree_feature_importances.png\")\n",
    "\n",
    "print(\"\\n=== MODEL EVALUATION COMPLETE ===\")\n",
    "print(f\"Logistic Regression AUC: {log_auc:.4f}\")\n",
    "print(f\"Decision Tree AUC:       {tree_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d5a025-d122-47de-8d39-51550f263bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
